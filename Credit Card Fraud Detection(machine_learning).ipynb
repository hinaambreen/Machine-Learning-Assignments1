{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1import different libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import models,layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.Load Data\n",
    "ccard_data = pd.read_csv(\"C:\\\\Users\\\\hina\\\\Downloads\\\\archive(6)\\\\creditcard.csv\")\n",
    "ccard_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.Check Missing Values \n",
    "ccard_data.isnull().any()\n",
    "ccard_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    284315\n",
       "1       492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccard_data[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting for fraud(1) and not fraud(0)\n",
    "fraud = pd.value_counts(ccard_data[\"Class\"])\n",
    "fraud.plot(kind=\"bar\",rot=0)\n",
    "plt.title(\"Fraud detection\")\n",
    "plt.xticks(range(2))\n",
    "plt.xlabel(\"class\")\n",
    "plt.ylabel(\"frequency\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "ccard_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ccard_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V20       V21       V22       V23       V24  \\\n",
       "0  0.098698  0.363787  ...  0.251412 -0.018307  0.277838 -0.110474  0.066928   \n",
       "1  0.085102 -0.255425  ... -0.069083 -0.225775 -0.638672  0.101288 -0.339846   \n",
       "2  0.247676 -1.514654  ...  0.524980  0.247998  0.771679  0.909412 -0.689281   \n",
       "3  0.377436 -1.387024  ... -0.208038 -0.108300  0.005274 -0.190321 -1.175575   \n",
       "4 -0.270533  0.817739  ...  0.408542 -0.009431  0.798278 -0.137458  0.141267   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  \n",
       "0  0.128539 -0.189115  0.133558 -0.021053  149.62  \n",
       "1  0.167170  0.125895 -0.008983  0.014724    2.69  \n",
       "2 -0.327642 -0.139097 -0.055353 -0.059752  378.66  \n",
       "3  0.647376 -0.221929  0.062723  0.061458  123.50  \n",
       "4 -0.206010  0.502292  0.219422  0.215153   69.99  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split ccard data into features and dependend variables\n",
    "dependent = ccard_data[\"Class\"]\n",
    "features = ccard_data.drop([\"Class\"],axis=1)\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#4.Split into 50% Training(Samples,Labels) , 30% Test(Samples,Labels) and 20% Validation Data(Samples,Labels).\n",
    "train_features,test_features,train_dependent,test_dependent = train_test_split(features,dependent,test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3.Standardized the Input Variables.\n",
    "mean = train_features.mean(axis=0)\n",
    "train_features -= mean\n",
    "std = train_features.std(axis=0)\n",
    "train_features /= std\n",
    "test_features -= mean\n",
    "test_features /= std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161145</th>\n",
       "      <td>0.402559</td>\n",
       "      <td>-0.067419</td>\n",
       "      <td>0.066209</td>\n",
       "      <td>-0.427935</td>\n",
       "      <td>-0.703356</td>\n",
       "      <td>1.326638</td>\n",
       "      <td>1.310292</td>\n",
       "      <td>0.405966</td>\n",
       "      <td>0.523778</td>\n",
       "      <td>0.015398</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.081846</td>\n",
       "      <td>-0.084033</td>\n",
       "      <td>0.007304</td>\n",
       "      <td>0.400189</td>\n",
       "      <td>-4.075964</td>\n",
       "      <td>-1.707842</td>\n",
       "      <td>0.700554</td>\n",
       "      <td>0.764063</td>\n",
       "      <td>0.230266</td>\n",
       "      <td>-0.165692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204520</th>\n",
       "      <td>0.853045</td>\n",
       "      <td>1.082568</td>\n",
       "      <td>0.010195</td>\n",
       "      <td>-0.997701</td>\n",
       "      <td>0.080656</td>\n",
       "      <td>0.438361</td>\n",
       "      <td>-0.250645</td>\n",
       "      <td>0.163259</td>\n",
       "      <td>-0.216419</td>\n",
       "      <td>0.348359</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.112308</td>\n",
       "      <td>-0.443007</td>\n",
       "      <td>-1.083151</td>\n",
       "      <td>0.425956</td>\n",
       "      <td>0.108640</td>\n",
       "      <td>-0.261293</td>\n",
       "      <td>0.423241</td>\n",
       "      <td>-0.170159</td>\n",
       "      <td>-0.177599</td>\n",
       "      <td>-0.352238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182659</th>\n",
       "      <td>0.646287</td>\n",
       "      <td>-0.044312</td>\n",
       "      <td>0.101926</td>\n",
       "      <td>1.038203</td>\n",
       "      <td>0.484459</td>\n",
       "      <td>0.163546</td>\n",
       "      <td>0.830013</td>\n",
       "      <td>1.285432</td>\n",
       "      <td>-0.904557</td>\n",
       "      <td>0.692976</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068198</td>\n",
       "      <td>0.020632</td>\n",
       "      <td>1.461860</td>\n",
       "      <td>-0.652604</td>\n",
       "      <td>1.193398</td>\n",
       "      <td>-0.330269</td>\n",
       "      <td>-1.273131</td>\n",
       "      <td>-2.996057</td>\n",
       "      <td>-3.509157</td>\n",
       "      <td>0.330885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25117</th>\n",
       "      <td>-1.290099</td>\n",
       "      <td>0.688560</td>\n",
       "      <td>-0.321166</td>\n",
       "      <td>0.367026</td>\n",
       "      <td>-0.444611</td>\n",
       "      <td>-0.834835</td>\n",
       "      <td>-0.641811</td>\n",
       "      <td>-0.523042</td>\n",
       "      <td>-0.025306</td>\n",
       "      <td>-0.594085</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.087169</td>\n",
       "      <td>-0.019907</td>\n",
       "      <td>-0.247870</td>\n",
       "      <td>0.283511</td>\n",
       "      <td>0.573862</td>\n",
       "      <td>0.290526</td>\n",
       "      <td>-0.839002</td>\n",
       "      <td>0.034342</td>\n",
       "      <td>0.049675</td>\n",
       "      <td>-0.336066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227642</th>\n",
       "      <td>1.060056</td>\n",
       "      <td>-0.777709</td>\n",
       "      <td>0.392470</td>\n",
       "      <td>0.406749</td>\n",
       "      <td>-0.396457</td>\n",
       "      <td>0.612565</td>\n",
       "      <td>-0.386883</td>\n",
       "      <td>0.803572</td>\n",
       "      <td>-0.078732</td>\n",
       "      <td>-0.057029</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.095765</td>\n",
       "      <td>-0.297960</td>\n",
       "      <td>-0.540300</td>\n",
       "      <td>-0.341307</td>\n",
       "      <td>0.971563</td>\n",
       "      <td>1.303019</td>\n",
       "      <td>1.076136</td>\n",
       "      <td>0.162199</td>\n",
       "      <td>0.453376</td>\n",
       "      <td>0.005211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "161145  0.402559 -0.067419  0.066209 -0.427935 -0.703356  1.326638  1.310292   \n",
       "204520  0.853045  1.082568  0.010195 -0.997701  0.080656  0.438361 -0.250645   \n",
       "182659  0.646287 -0.044312  0.101926  1.038203  0.484459  0.163546  0.830013   \n",
       "25117  -1.290099  0.688560 -0.321166  0.367026 -0.444611 -0.834835 -0.641811   \n",
       "227642  1.060056 -0.777709  0.392470  0.406749 -0.396457  0.612565 -0.386883   \n",
       "\n",
       "              V7        V8        V9  ...       V20       V21       V22  \\\n",
       "161145  0.405966  0.523778  0.015398  ... -0.081846 -0.084033  0.007304   \n",
       "204520  0.163259 -0.216419  0.348359  ... -0.112308 -0.443007 -1.083151   \n",
       "182659  1.285432 -0.904557  0.692976  ...  0.068198  0.020632  1.461860   \n",
       "25117  -0.523042 -0.025306 -0.594085  ... -0.087169 -0.019907 -0.247870   \n",
       "227642  0.803572 -0.078732 -0.057029  ... -0.095765 -0.297960 -0.540300   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \n",
       "161145  0.400189 -4.075964 -1.707842  0.700554  0.764063  0.230266 -0.165692  \n",
       "204520  0.425956  0.108640 -0.261293  0.423241 -0.170159 -0.177599 -0.352238  \n",
       "182659 -0.652604  1.193398 -0.330269 -1.273131 -2.996057 -3.509157  0.330885  \n",
       "25117   0.283511  0.573862  0.290526 -0.839002  0.034342  0.049675 -0.336066  \n",
       "227642 -0.341307  0.971563  1.303019  1.076136  0.162199  0.453376  0.005211  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>183484</th>\n",
       "      <td>0.653087</td>\n",
       "      <td>-0.164828</td>\n",
       "      <td>0.639652</td>\n",
       "      <td>-0.030862</td>\n",
       "      <td>-0.428981</td>\n",
       "      <td>0.921513</td>\n",
       "      <td>-0.068904</td>\n",
       "      <td>0.946129</td>\n",
       "      <td>-0.100924</td>\n",
       "      <td>-0.158665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241451</td>\n",
       "      <td>-0.278545</td>\n",
       "      <td>-0.596280</td>\n",
       "      <td>-0.415413</td>\n",
       "      <td>-0.077669</td>\n",
       "      <td>0.405079</td>\n",
       "      <td>0.017415</td>\n",
       "      <td>0.270598</td>\n",
       "      <td>0.495996</td>\n",
       "      <td>-0.197751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255448</th>\n",
       "      <td>1.314436</td>\n",
       "      <td>-0.178265</td>\n",
       "      <td>0.564330</td>\n",
       "      <td>0.095287</td>\n",
       "      <td>-0.464169</td>\n",
       "      <td>0.855732</td>\n",
       "      <td>-0.551798</td>\n",
       "      <td>0.824502</td>\n",
       "      <td>-0.056988</td>\n",
       "      <td>-0.274309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125844</td>\n",
       "      <td>-0.365220</td>\n",
       "      <td>-1.145077</td>\n",
       "      <td>-0.047845</td>\n",
       "      <td>0.808978</td>\n",
       "      <td>-0.777494</td>\n",
       "      <td>0.279021</td>\n",
       "      <td>0.191643</td>\n",
       "      <td>0.540395</td>\n",
       "      <td>-0.352238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244749</th>\n",
       "      <td>1.214141</td>\n",
       "      <td>-0.822501</td>\n",
       "      <td>-1.450411</td>\n",
       "      <td>0.216076</td>\n",
       "      <td>0.469114</td>\n",
       "      <td>1.732071</td>\n",
       "      <td>-1.336037</td>\n",
       "      <td>-0.928354</td>\n",
       "      <td>0.273756</td>\n",
       "      <td>0.819949</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544500</td>\n",
       "      <td>0.943456</td>\n",
       "      <td>1.559198</td>\n",
       "      <td>1.534325</td>\n",
       "      <td>1.058354</td>\n",
       "      <td>-3.458323</td>\n",
       "      <td>-2.160497</td>\n",
       "      <td>0.713920</td>\n",
       "      <td>1.346184</td>\n",
       "      <td>0.029794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63919</th>\n",
       "      <td>-0.923635</td>\n",
       "      <td>-1.261742</td>\n",
       "      <td>0.520884</td>\n",
       "      <td>0.951650</td>\n",
       "      <td>0.741141</td>\n",
       "      <td>-1.355350</td>\n",
       "      <td>1.564413</td>\n",
       "      <td>0.417365</td>\n",
       "      <td>-0.199135</td>\n",
       "      <td>-0.236750</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.282973</td>\n",
       "      <td>1.090082</td>\n",
       "      <td>0.951407</td>\n",
       "      <td>0.239021</td>\n",
       "      <td>-0.431423</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>-0.368902</td>\n",
       "      <td>-1.271772</td>\n",
       "      <td>-2.033400</td>\n",
       "      <td>0.891215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11475</th>\n",
       "      <td>-1.576858</td>\n",
       "      <td>0.681681</td>\n",
       "      <td>-0.328576</td>\n",
       "      <td>0.487185</td>\n",
       "      <td>-0.150376</td>\n",
       "      <td>-0.809900</td>\n",
       "      <td>-0.395533</td>\n",
       "      <td>-0.652954</td>\n",
       "      <td>-0.050887</td>\n",
       "      <td>0.904759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165271</td>\n",
       "      <td>-0.187534</td>\n",
       "      <td>-0.102658</td>\n",
       "      <td>0.106991</td>\n",
       "      <td>0.549746</td>\n",
       "      <td>0.726612</td>\n",
       "      <td>-0.557469</td>\n",
       "      <td>-0.006838</td>\n",
       "      <td>0.010024</td>\n",
       "      <td>-0.339967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Time        V1        V2        V3        V4        V5        V6  \\\n",
       "183484  0.653087 -0.164828  0.639652 -0.030862 -0.428981  0.921513 -0.068904   \n",
       "255448  1.314436 -0.178265  0.564330  0.095287 -0.464169  0.855732 -0.551798   \n",
       "244749  1.214141 -0.822501 -1.450411  0.216076  0.469114  1.732071 -1.336037   \n",
       "63919  -0.923635 -1.261742  0.520884  0.951650  0.741141 -1.355350  1.564413   \n",
       "11475  -1.576858  0.681681 -0.328576  0.487185 -0.150376 -0.809900 -0.395533   \n",
       "\n",
       "              V7        V8        V9  ...       V20       V21       V22  \\\n",
       "183484  0.946129 -0.100924 -0.158665  ...  0.241451 -0.278545 -0.596280   \n",
       "255448  0.824502 -0.056988 -0.274309  ... -0.125844 -0.365220 -1.145077   \n",
       "244749 -0.928354  0.273756  0.819949  ...  0.544500  0.943456  1.559198   \n",
       "63919   0.417365 -0.199135 -0.236750  ... -1.282973  1.090082  0.951407   \n",
       "11475  -0.652954 -0.050887  0.904759  ... -0.165271 -0.187534 -0.102658   \n",
       "\n",
       "             V23       V24       V25       V26       V27       V28    Amount  \n",
       "183484 -0.415413 -0.077669  0.405079  0.017415  0.270598  0.495996 -0.197751  \n",
       "255448 -0.047845  0.808978 -0.777494  0.279021  0.191643  0.540395 -0.352238  \n",
       "244749  1.534325  1.058354 -3.458323 -2.160497  0.713920  1.346184  0.029794  \n",
       "63919   0.239021 -0.431423  0.009186 -0.368902 -1.271772 -2.033400  0.891215  \n",
       "11475   0.106991  0.549746  0.726612 -0.557469 -0.006838  0.010024 -0.339967  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5.Model : input Layer (No. of features ), 3 hidden layers including 10,8,6 unit & Output Layer with activation function relu/tanh (check by experiment).\n",
    "#6.Compilation Step (Note : Its a Binary problem , select loss , metrics according to it)\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(10,activation=\"relu\",input_shape=(train_features.shape[1],)))\n",
    "model.add(layers.Dense(8,activation=\"relu\"))\n",
    "model.add(layers.Dense(6,activation=\"relu\"))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer=\"rmsprop\",loss = \"binary_crossentropy\",metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1247/1247 [==============================] - 3s 2ms/step - loss: 0.1583 - accuracy: 0.9716 - val_loss: 0.0050 - val_accuracy: 0.9994\n",
      "Epoch 2/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9994\n",
      "Epoch 3/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "Epoch 4/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "Epoch 5/100\n",
      "1247/1247 [==============================] - 2s 2ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.0038 - val_accuracy: 0.9995\n",
      "Epoch 6/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0044 - accuracy: 0.9993 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "Epoch 7/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0033 - accuracy: 0.9995 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "Epoch 8/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "Epoch 9/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0040 - accuracy: 0.9994 - val_loss: 0.0033 - val_accuracy: 0.9993\n",
      "Epoch 10/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "Epoch 11/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "Epoch 12/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0041 - val_accuracy: 0.9994\n",
      "Epoch 13/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
      "Epoch 14/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "Epoch 15/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0030 - val_accuracy: 0.9994\n",
      "Epoch 16/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.9993 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 17/100\n",
      "1247/1247 [==============================] - 2s 2ms/step - loss: 0.0042 - accuracy: 0.9993 - val_loss: 0.0033 - val_accuracy: 0.9993\n",
      "Epoch 18/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 19/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0034 - val_accuracy: 0.9993\n",
      "Epoch 20/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "Epoch 21/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "Epoch 22/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 23/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 24/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0034 - val_accuracy: 0.9993\n",
      "Epoch 25/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0034 - val_accuracy: 0.9993\n",
      "Epoch 26/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 27/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0033 - val_accuracy: 0.9993\n",
      "Epoch 28/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 29/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0034 - val_accuracy: 0.9993\n",
      "Epoch 30/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 31/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 32/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0033 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9994\n",
      "Epoch 33/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0031 - val_accuracy: 0.9994\n",
      "Epoch 34/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "Epoch 35/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 36/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 37/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 38/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0029 - accuracy: 0.9994 - val_loss: 0.0050 - val_accuracy: 0.9993\n",
      "Epoch 39/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 40/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0034 - val_accuracy: 0.9993\n",
      "Epoch 41/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0031 - val_accuracy: 0.9993\n",
      "Epoch 42/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0034 - val_accuracy: 0.9993\n",
      "Epoch 43/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 44/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0031 - val_accuracy: 0.9993\n",
      "Epoch 45/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0025 - accuracy: 0.9995 - val_loss: 0.0040 - val_accuracy: 0.9993\n",
      "Epoch 46/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 47/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "Epoch 48/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
      "Epoch 49/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 50/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0033 - val_accuracy: 0.9993\n",
      "Epoch 51/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0051 - val_accuracy: 0.9994\n",
      "Epoch 52/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "Epoch 53/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "Epoch 54/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "Epoch 55/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0026 - accuracy: 0.9995 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
      "Epoch 56/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0038 - val_accuracy: 0.9994\n",
      "Epoch 57/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0049 - val_accuracy: 0.9994\n",
      "Epoch 58/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "Epoch 59/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "Epoch 60/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "Epoch 61/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0033 - val_accuracy: 0.9994\n",
      "Epoch 62/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0037 - accuracy: 0.9994 - val_loss: 0.0040 - val_accuracy: 0.9994\n",
      "Epoch 63/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0036 - val_accuracy: 0.9994\n",
      "Epoch 64/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 65/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0027 - accuracy: 0.9995 - val_loss: 0.0034 - val_accuracy: 0.9993\n",
      "Epoch 66/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 67/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
      "Epoch 68/100\n",
      "1247/1247 [==============================] - 1s 1ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0037 - val_accuracy: 0.9994\n",
      "Epoch 69/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
      "Epoch 70/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0034 - val_accuracy: 0.9994\n",
      "Epoch 71/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0032 - val_accuracy: 0.9994\n",
      "Epoch 72/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 73/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "Epoch 74/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0032 - val_accuracy: 0.9993\n",
      "Epoch 75/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 76/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 77/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0038 - val_accuracy: 0.9993\n",
      "Epoch 78/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0031 - val_accuracy: 0.9993\n",
      "Epoch 79/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0028 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9992\n",
      "Epoch 80/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 81/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0033 - val_accuracy: 0.9993\n",
      "Epoch 82/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0033 - val_accuracy: 0.9993\n",
      "Epoch 83/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0039 - accuracy: 0.9993 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "Epoch 84/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0031 - val_accuracy: 0.9993\n",
      "Epoch 85/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9994 - val_loss: 0.0048 - val_accuracy: 0.9993\n",
      "Epoch 86/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0035 - val_accuracy: 0.9993\n",
      "Epoch 87/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0035 - val_accuracy: 0.9994\n",
      "Epoch 88/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0034 - accuracy: 0.9994 - val_loss: 0.0036 - val_accuracy: 0.9993\n",
      "Epoch 89/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0030 - accuracy: 0.9994 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "Epoch 90/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0037 - val_accuracy: 0.9993\n",
      "Epoch 91/100\n",
      "1247/1247 [==============================] - 2s 2ms/step - loss: 0.0038 - accuracy: 0.9994 - val_loss: 0.0043 - val_accuracy: 0.9993\n",
      "Epoch 92/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0029 - accuracy: 0.9995 - val_loss: 0.0045 - val_accuracy: 0.9993\n",
      "Epoch 93/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0035 - accuracy: 0.9994 - val_loss: 0.0041 - val_accuracy: 0.9993\n",
      "Epoch 94/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0040 - accuracy: 0.9993 - val_loss: 0.0054 - val_accuracy: 0.9993\n",
      "Epoch 95/100\n",
      "1247/1247 [==============================] - 2s 2ms/step - loss: 0.0034 - accuracy: 0.9995 - val_loss: 0.0039 - val_accuracy: 0.9993\n",
      "Epoch 96/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0037 - accuracy: 0.9993 - val_loss: 0.0042 - val_accuracy: 0.9993\n",
      "Epoch 97/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0032 - accuracy: 0.9995 - val_loss: 0.0050 - val_accuracy: 0.9993\n",
      "Epoch 98/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0030 - accuracy: 0.9995 - val_loss: 0.0050 - val_accuracy: 0.9993\n",
      "Epoch 99/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0036 - accuracy: 0.9994 - val_loss: 0.0047 - val_accuracy: 0.9993\n",
      "Epoch 100/100\n",
      "1247/1247 [==============================] - 2s 1ms/step - loss: 0.0039 - accuracy: 0.9994 - val_loss: 0.0045 - val_accuracy: 0.9993\n"
     ]
    }
   ],
   "source": [
    "#7.Train the Model with Epochs (100).\n",
    "#8.If the model gets overfit tune your model by changing the units , No. of layers , epochs , add dropout layer or add Regularizer according to the need .\n",
    "history = model.fit(train_features,train_dependent, batch_size=128, epochs=100, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2671/2671 [==============================] - 3s 1ms/step - loss: 0.0057 - accuracy: 0.9994\n"
     ]
    }
   ],
   "source": [
    "#9.Prediction should be > 92%\n",
    "#10.Evaluation Step\n",
    "loss,acc = model.evaluate(test_features,test_dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2832880e-04],\n",
       "       [1.0267628e-04],\n",
       "       [3.1044857e-07],\n",
       "       [1.7898882e-06],\n",
       "       [7.1321911e-06],\n",
       "       [1.6957521e-04],\n",
       "       [1.8620227e-07],\n",
       "       [6.5022132e-06],\n",
       "       [2.0447169e-06],\n",
       "       [2.2013355e-06]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#11.Prediction \n",
    "pred = model.predict(test_features)\n",
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.round(pred)\n",
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
